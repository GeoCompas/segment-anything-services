{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending a request to the torchserve encoder service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import httpx\n",
    "import base64\n",
    "from PIL import Image\n",
    "from PIL.ImageOps import equalize, autocontrast\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "encode_url=\"http://127.0.0.1:8080/predictions/sam_vit_h_encode\" # make sure to select correct port. 70* for cpu, 80* for gpu\n",
    "#encode_url = \"https://segme-gpuel-ekfao79wi98g-617785108.us-east-1.elb.amazonaws.com/predictions/sam_vit_h_encode\"\n",
    "pth_fox = \"../data/sample-img-fox.jpg\"\n",
    "input_point_fox = (150, 75)\n",
    "\n",
    "pth_slick = \"../data/tile_with_slick_512_512.png\"\n",
    "input_point_not_on_slick = (10, 120)\n",
    "input_point_on_slick = (6, 120)\n",
    "input_label = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_fox = Image.open(pth_fox)\n",
    "img_fox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image.open(\"../data/wuPwKFUZ.jpeg\").size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_slick = Image.open(pth_slick)\n",
    "autocontrast(img_slick, cutoff=0, ignore=None, mask=None, preserve_tone=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "def generate_dummy_array_and_encode(shape):\n",
    "    # Create a dummy 3-channel numpy array with the given shape\n",
    "    dummy_array = np.random.randint(0, 256, size=(shape[0], shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # Convert the numpy array to an image\n",
    "    img = Image.fromarray(dummy_array)\n",
    "\n",
    "    # Save the image to a buffer in PNG format\n",
    "    buffer = io.BytesIO()\n",
    "    img.save(buffer, format='PNG')\n",
    "    buffer.seek(0)\n",
    "\n",
    "    # Encode the buffer content as base64\n",
    "    encoded_image = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "    # Store the encoded image in a dictionary\n",
    "    result = {'encoded_image': encoded_image}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing arbitrarily sized images, 2049 or greater should error 500 with detailed message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shape = (2049, 2049)\n",
    "payload = generate_dummy_array_and_encode(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "try:\n",
    "    response = httpx.post(encode_url, json=payload, timeout=None)\n",
    "except (BrokenPipeError, httpx.RemoteProtocolError) as e:\n",
    "    print(\"wait and try again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reads image as bytes, converts bytes to string so it can be sent as a post request\n",
    "with open(pth_slick, 'rb') as f:\n",
    "    byte_string = f.read()\n",
    "    base64_string = base64.b64encode(byte_string).decode('utf-8')\n",
    "\n",
    "payload = {\"encoded_image\": base64_string}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Time to encode image on 1080 Ti GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "try:\n",
    "    response = httpx.post(encode_url, json=payload, timeout=None)\n",
    "except (BrokenPipeError, httpx.RemoteProtocolError) as e:\n",
    "    print(\"wait and try again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image embeddings for the image above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_embedding_string = response.json()['image_embedding']\n",
    "base64_bytes = base64.b64decode(encoded_embedding_string)\n",
    "image_embedding = np.frombuffer(base64_bytes, dtype=np.float32)\n",
    "image_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending the image embeddings to the decoder service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_shape = np.array(img_slick).shape\n",
    "decode_payload = {\n",
    "    \"image_embeddings\": encoded_embedding_string,\n",
    "    \"image_shape\": img_shape,\n",
    "    \"input_label\": input_label,\n",
    "    \"input_point\": input_point_on_slick\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "decode_url=\"http://127.0.0.1:8080/predictions/sam_vit_h_decode\" # make sure to select correct port. 70* for cpu, 80* for gpu\n",
    "#decode_url=\"https://sas.ds.io/predictions/sam_vit_h_decode\"\n",
    "response = httpx.post(decode_url, json=decode_payload, timeout=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_masks_string = response.json()['masks']\n",
    "base64_bytes_masks = base64.b64decode(encoded_masks_string)\n",
    "masks = np.frombuffer(base64_bytes_masks, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We reshape the masks to the original image shape, adding a channel for the alpha channel, so it is 4 instead of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "masks = masks.reshape((1, 4, 512, 512))\n",
    "masks = masks > .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With our encoder and decoder service, we get a solid mask prediction by just supplying a point on the object of interest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_mask(mask, ax):\n",
    "    color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(np.array(img_slick))\n",
    "show_mask(masks[:,0,:,:], plt.gca())\n",
    "input_point_arr = np.array(input_point_on_slick)[np.newaxis,:]\n",
    "input_label_arr = np.array(input_label)[np.newaxis]\n",
    "show_points(input_point_arr, input_label_arr, plt.gca())\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "ade40eea8fb25e5537d38c9712098de53166edee9e4eddbf94249e69ca5e97d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
